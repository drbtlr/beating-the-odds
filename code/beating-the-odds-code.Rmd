---
title: "Beating the Odds"
author: "Aaron Butler & Hannah Poquette"
date: "May XX, 2020"
output: 
  html_document:
    theme: simplex
    css: ../includes/styles.css
    highlight: NULL
    keep_md: true
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

# Implementing a Beating the Odds Analysis 

*A step-by-step guide to implementing a beating the odds (BTO) analysis using a multilevel framework. Programmed in R.*

```{r knitrSetup, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE, comment=NA}
# Set options for knitr
library(knitr)
knitr::opts_chunk$set(comment=NA, warning=FALSE, echo=TRUE,
                      root.dir = normalizePath("../"),
                      error=FALSE, message=FALSE, fig.align='center',
                      fig.width=8, fig.height=6, dpi = 144, 
                      fig.path = "../figure/E_", 
                      cache.path = "../cache/E_")
options(width=80)
```

<div class="navbar navbar-default navbar-fixed-top" id="logo">
<div class="container">
<img src="https://opensdp.github.io/assets/images/OpenSDP-Banner_crimson.jpg" style="display: block; margin: 0 auto; height: 115px;">
</div>
</div>

## Getting Started

### Objective

In this guide, you will use statistical models to predict school performance based on the demographic makeup of schools' student populations and compare these predictions with actual school performance. 

### Purpose and Overview of Analyses

School leaders often want to identify promising practices that distinguish high-performing schools from their counterparts and facilitate the transfer of some of these practices to struggling schools. A beating the odds analysis is one approach school leaders can take to identify schools that perform better or worse than expected, given the unique student populations they serve.

The purpose of this guide is to present a data-driven approach to identify beating-the-odds schools. We use multilevel models to predict student performance and school-level effects on that performance. Next, we compare each school's predicted performance to its actual performance. The school is identified as beating the odds if its actual performance is higher or lower than predicted by a statistically significant margin. The procedures presented in this guide parallel those used in a collaborative study by the [Kentucky Department of Education](https://education.ky.gov/) and [REL Appalachia](https://ies.ed.gov/ncee/edlabs/regions/appalachia/).

### Using this Guide

This guide utilizes SDP's ["Faketucky"](https://github.com/opensdp/faketucky), a synthetic dataset based on real student data. While the data is synthetic, the code is not. Schools and districts wanting to conduct their own beating the odds analysis can easily adapt the code provided in this guide to their own data.

Once you have identified analyses that you want to replicate or modify, click the "Download" buttons to download R code and sample data. You can make changes to the charts using the code and sample data, or modify the code to work with your own data. If you are familiar with GitHub, you can click "Go to Repository" and clone the entire repository to your own computer. 

Go to the Participate page to read about more ways to engage with the OpenSDP community or reach out for assistance in adapting this code for your specific context.

### Installing and Loading R Packages

To complete this tutorial, you will need R, R Studio, and the following R packages installed on your machine: 

- `tidyverse`: For convenient data and output manipulation
- `lme4`: To fit multilevel models

To install packages, such as `lme4`, run the following command in the R console:

`install.packages("lme4")`

In addition, this guide will draw from OpenSDP-written functions defined in the `functions.R` document, which is located in the `R` folder of this guide's GitHub repository. Please make sure to have downloaded the entire GitHub repository to run this code.

After installing your R packages and downloaded this guide's GitHub repository, run the chunk of code below to load them onto your computer.

```{r load-packages, echo=TRUE}
# Load packages
library(tidyverse)
library(lme4)

# Read in some R functions that are convenience wrappers
source("../R/functions.R")
```

### About the Data

This guide uses SDP's ["Faketucky"](https://github.com/opensdp/faketucky) dataset. The Faketucky synthetic college-going analysis file contains high school and college outcome data for two graduating cohorts of approximately 40,000 students. There are no real children in the dataset, but it mirrors the relationships between variables present in real data. The dataset was developed as an offshoot of [SDP's College-Going Diagnostic for Kentucky](https://cepr.harvard.edu/publications/sdp-college-going-diagnostic-kentucky), using the R [synthpop](https://cran.r-project.org/web/packages/synthpop/index.html) package. In addition, we created school-level aggregates for each variable. The first step of the analysis "Prepare data for analysis" describes the steps to create the school-level variables.

Below is a list of variables and descriptions used in the analyses:

| Variable Name        | Variable Description                                                 |
|:-----------          |:------------------                                                   |
| `first_dist_code`    | Code of first district attended in high school                       |
| `first_dist_name`    | Name of first district attended in high school                       |
| `first_hs_code`      | Code of first high school attended                                   |
| `first_hs_name`      | Name of first high school attended                                   |
| `chrt_ninth`         | Student 9th grade cohort                                             |
| `male`               | Student male indicator                                               |
| `race_ethnicity`     | Student race/ethnicity                                               |
| `frpl_ever_in_hs`    | Student ever received free or reduced price lunch in high school     |
| `sped_ever_in_hs`    | Student ever classified as special ed in high school                 |
| `lep_ever_in_hs`     | Student ever classified as limited English proficiency in high school|
| `gifted_ever_in_hs`  | Student ever classified as gifted in high school                     |
| `scale_score_8_math` | Scaled score of 8th grade math test                                  |
| `scale_score_8_read` | Scaled score of 8th grade reading test                               |
| `scale_score_11_math`| Scaled score of highest math ACT                                     |
| `scale_score_11_read`| Scaled score of highest reading ACT                                  |

#### Loading the Dataset

```{r load-data, echo=TRUE}
# Load "Faketucky" data file
load("../data/faketucky.rda")

# Select variables of interest
my_vars <- c("first_dist_code", "first_dist_name", "first_hs_code", 
             "first_hs_name", "chrt_ninth", "male", "race_ethnicity", 
             "frpl_ever_in_hs", "sped_ever_in_hs", "lep_ever_in_hs", 
             "lep_ever_in_hs", "gifted_ever_in_hs", "scale_score_8_math",
             "scale_score_8_read", "scale_score_11_math", "scale_score_11_read")

faketucky <- faketucky_20160923 %>% 
  select(my_vars)
```

### Giving Feedback on this Guide
 
This guide is an open-source document hosted on GitHub and generated using R Markdown. We welcome feedback, corrections, additions, and updates. Please visit the OpenSDP [participate repository](https://opensdp.github.io/participate/) to read our contributor guidelines.

## Analyses

### Identify BTO Schools

**Purpose:** This analysis illustrates how to identify schools that perform better or worse than expected, given the unique student populations they serve, using a beating-the-odds approach. 

**Required Analysis File Variables:**

- `first_hs_code`
- `chrt_ninth`
- `male`
- `race_ethnicity`
- `frpl_ever_in_hs`
- `sped_ever_in_hs`
- `lep_ever_in_hs`
- `gifted_ever_in_hs`
- `scale_score_8_math`
- `scale_score_8_read`
- `scale_score_11_math`
- `scale_score_11_read`

**Analytic Technique:** We use multilevel models to predict student performance and school-level effects on that performance. There are a number of benefits to using a multilevel approach over a more traditional approach like ordinary least squares. In particular, a multilevel approach allows us to account for the hierarchical or nested structure of the data. In this case, student observations and school observations from different years are nested within schools. Additionally, recent beating-the-odds studies have used a multilevel approach with success (e.g., [Bowers, 2015](https://www.tandfonline.com/doi/full/10.1080/13632434.2014.962500); [Partridg, Rudo, & Herrera, 2017](https://eric.ed.gov/?id=ED572602)). 

We encourage you check out Gelman and Hill's book [Data Analysis Using Regression and Multilevel/Hierarchical Models](http://www.stat.columbia.edu/~gelman/arm/) if you're interested in learning more about multilevel models and their applications.

**Ask Yourself:**

- What is the structure of my data? How might it influence the model?
- What variables do I want to include in the model? 
- What students will be included in or excluded from the model?
- What metrics will I use to determine appropriate model fit?

**A Note on Missing Data:** It is important to determine how you want to address missing data before you begin your analysis. For simplicity, we choose to exclude students with data missing from the analyses. We recommend that you conduct a missing data analysis to determine whether your data is missing completely at random, missing at random, or missing not at random and apply the appropriate strategy to address your missing data. Andrew Gelman's chapter on [Missing-data Imputation in R](http://www.stat.columbia.edu/~gelman/arm/missing.pdf) is a great resource to help you think about your options.   

#### Step 1: Prepare data for analysis

This beating-the-odds analysis uses a multilevel framework that incorporates school-level information into the modeling process. To prepare the analytical dataset, we calculated school averages within each school year. These variables where then centered using the grand mean of each variable. 

*Note:* We recognize that grand-mean centering may not be an appropriate option for your analysis. We encourage you to explore other centering techniques for multilevel modeling. Gelman and Hill's [Data Analysis Using Regression and Multilevel/Hierarchical Models](http://www.stat.columbia.edu/~gelman/arm/) and Raudenbush and Bryk's [Hierarchical Linear Models](https://us.sagepub.com/en-us/nam/hierarchical-linear-models/book9230) provide further details on the different centering techniques as well as the advantages and disadvantages of their use in multilevel modeling. 

```{r prep-data, echo=TRUE}
# // Step 1.1: Create school averages within year
df_sch_avg <- faketucky %>% 
  # Create indicator for students identifying as white
  mutate(race_white = ifelse(race_ethnicity == "White", 1, 0)) %>% 
  # Group data by high school and cohort year
  group_by(first_hs_code, chrt_ninth) %>% 
  # Calculate school averages within year
  mutate(sch_male = mean(male, na.rm = TRUE),
         sch_white = mean(race_white, na.rm = TRUE),
         sch_frpl = mean(frpl_ever_in_hs, na.rm = TRUE),
         sch_sped = mean(sped_ever_in_hs, na.rm = TRUE),
         sch_lep = mean(lep_ever_in_hs, na.rm = TRUE),
         sch_gifted = mean(gifted_ever_in_hs, na.rm = TRUE),
         sch_8_math = mean(scale_score_8_math, na.rm = TRUE),
         sch_8_read = mean(scale_score_8_read, na.rm = TRUE)) %>% 
  # Remember to ungroup
  ungroup()

# // Step 1.2: Center variables around grand mean within year
df_center <- df_sch_avg %>% 
  # Flag 2010 cohort
  mutate(flag_2010_cohort = ifelse(chrt_ninth == 2010, 1, 0)) %>% 
  # Group by cohort year
  group_by(chrt_ninth) %>% 
  # Center student-level variables
  mutate(
    scale_score_8_math_center = scale_score_8_math - mean(scale_score_8_math, 
                                                          na.rm = TRUE),
    scale_score_8_read_center = scale_score_8_read - mean(scale_score_8_read, 
                                                          na.rm = TRUE)) %>% 
  # Calculate within year mean for school-level variables
  mutate(sch_male_mean_year = mean(sch_male, na.rm = TRUE),
         sch_white_mean_year = mean(sch_white, na.rm = TRUE),
         sch_frpl_mean_year = mean(sch_frpl, na.rm = TRUE),
         sch_sped_mean_year = mean(sch_sped, na.rm = TRUE),
         sch_lep_mean_year = mean(sch_lep, na.rm = TRUE),
         sch_gifted_mean_year = mean(sch_gifted, na.rm = TRUE),
         sch_8_math_mean_year = mean(sch_8_math, na.rm = TRUE),
         sch_8_read_mean_year = mean(sch_8_read, na.rm = TRUE)) %>% 
  # Ungroup
  ungroup() %>% 
  # Center school-level variables
  mutate(sch_male_center = sch_male - sch_male_mean_year,
         sch_white_center = sch_white - sch_white_mean_year,
         sch_frpl_center = sch_frpl - sch_frpl_mean_year,
         sch_sped_center = sch_sped - sch_sped_mean_year,
         sch_lep_center = sch_lep - sch_lep_mean_year,
         sch_gifted_center = sch_gifted - sch_gifted_mean_year,
         sch_8_math_center = sch_8_math - sch_8_math_mean_year,
         sch_8_read_center = sch_8_read - sch_8_read_mean_year)
```

#### Step 2: Fit multilevel models

Multilevel models are a powerful and flexible extension to conventional regression frameworks. This is one of the many reasons why they are so attractive to education researchers. However, this added flexibility can make fitting and interpreting such models a challenge. Here, we present a relatively simple multilevel model that takes into account school-level variation. We encourage you to read more on the topic of multilevel modeling and its application in beating-the-odds analyses. 

We fit a two-level multilevel model for each subject area outcome of interest -- ACT math and reading -- using the `lmer` function in the `lme4` package. We recommend you read the [lme4 Reference Manual](https://cran.r-project.org/web/packages/lme4/lme4.pdf) and vignette [Fitting Linear Mixed-Effects Models Using lme4](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) before you fit your models. These resources contain a wealth of information. 

```{r fit-models, echo=TRUE}
# // Step 2: Fit multilevel models for each subject area  
m_math <- lmer(
  # Define model formula
  formula = scale_score_11_math ~ 
    male + race_white + frpl_ever_in_hs + sped_ever_in_hs + 
    lep_ever_in_hs + gifted_ever_in_hs + scale_score_8_math_center + 
    sch_male_center + sch_white_center + sch_frpl_center +
    sch_sped_center + sch_lep_center + sch_gifted_center +
    sch_8_math_center + flag_2010_cohort + (1|first_hs_code),
  # Call dataframe containing the variables named in formula
  data = df_center, 
  # Option to use restricted maximum likelihood (REML) estimates
  REML = TRUE
)

m_read <- lmer(
  formula = scale_score_11_read ~ 
    male + race_white + frpl_ever_in_hs + sped_ever_in_hs + 
    lep_ever_in_hs + gifted_ever_in_hs + scale_score_8_read_center + 
    sch_male_center + sch_white_center + sch_frpl_center +
    sch_sped_center + sch_lep_center + sch_gifted_center +
    sch_8_read_center + flag_2010_cohort + (1|first_hs_code),
  data = df_center, REML = TRUE
)
```

#### Step 3: Inspect Summary Statistics for Model Fit

Examine the coefficients and standard errors for each variable. Ask yourself if the estimates are in the range of reasonable possiblity. If not, go back and inspect your dataset and make sure there are no errors in processing the data. Also inspect your dataset to make sure that the assumptions of multilevel modeling hold. 

For information on other model checking and sensitivity analysis for multilevel models, see Snijders and Berkhof's chapter on [Diagnostic Checks for Multilevel Models](https://www.stats.ox.ac.uk/~snijders/handbook_ml_ch3.pdf).

```{r inspect-fit, echo=TRUE}
# // Step 3: Call model summary statistics
summary(m_math)
summary(m_read)
```

#### Step 4: Calculate statistics for beating-the-odds schools

We used the model residuals to identify schools that were beating the odds and performing better than expected. We also evaluated schools that were performing worse than expected as well. This information can be used to provide targeted support.

We constructed a 95 percent confidence interval around each school's residual, using the
formula: 

```95 percent confidence interval = School residual ±1.96 × Residual standard error.```

Confidence intervals allowed us to determination whether a value of zero was just as plausible as the estimated residual. We identified schools as beating the odds if the 95 percent confidence interval did not include zero.

```{r calc-bto, echo=TRUE}
# // Step 4.1: Access school-level residuals
resids_math <- ranef(m_math)
resids_read <- ranef(m_read)

# // Step 4.2: Create function to flag BTO schools 
calc_bto <- function(.resids) {
  # Imput model residuals
  .resids %>%
    # Store as a dataframe
    data.frame() %>% 
    # Set benchmark at +2 standard deviations
    mutate(pos_bench = condsd * 1.96,
           neg_bench = condsd * -1.96,) %>% 
    # Flag schools that perferm above/below benchmark (i.e., BTOs)
    mutate(sig = ifelse(condval >= pos_bench | 
                          condval <= neg_bench, 
                        "yes", "no"))
}

# // Step 4.3: Execute function for each subject area
bto_math <- calc_bto(resids_math) %>% 
  # Keep variables of interest. 
  # Note: we select and rename variables at the same time.
  select(first_hs_code = grp, resid_math = condval, bto_math = sig)
  
bto_read <- calc_bto(resids_read) %>% 
  select(first_hs_code = grp, resid_read = condval, bto_read = sig)

# // Step 4.4: Merge datsets for plotting

# Merge bto datasets
bto_read_math <- left_join(bto_read, bto_math, by = "first_hs_code") %>% 
  # Convert high school work to numeric for merge
  mutate(first_hs_code = as.numeric(first_hs_code))

# Pull school and district info from original dataset
df_names <- faketucky %>% 
  select(first_dist_code, first_hs_code, first_dist_name, first_hs_name) %>% 
  distinct()

# Merge bto and school info datasets
df_bto <- left_join(df_names, bto_read_math, by = "first_hs_code") 
```

#### Step 5: Plot beating-the-odds schools

It's always helpful to plot the results of your analysis. We've found a nice scatter plot of beating-the-odds schools can be an effective visualization for communicating the overall results of the analysis. 

```{r plot-bto, echo=TRUE}
# // Step 5: Create scatter plot math/read residuals
df_bto %>% 
  mutate(bto_both = ifelse(bto_math == "yes" & bto_read == "yes", 
                           "BTO School", "Not a BTO School")) %>% 
  filter(!is.na(bto_both)) %>%
  ggplot(aes(resid_math, resid_read, color = bto_both)) +
  geom_point(size = 2, alpha = .6) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values = c("#E69F00", "#999999")) +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 11),
        legend.position = "top",
        legend.text = element_text(size = 11)) +
  labs(x = "Math (actual - predicted)",
       y = "Reading (actual - predicted)",
       color = "",
       title = "Beating-the-Odds Schools in Math and Reading",
       subtitle = "Schools in upper-right corner are performing better than expected\nin math and reading, whereas schools in lower-left corner or under\nperforming in both subject areas.")
```

### BTO schools by performance

**Purpose:** This analysis examines the distribution of beating-the-odds schools by performance level in math and reading. Results provide an overall summary of a beating-the-odds analysis.  

**Required Analysis File Variables:**

- `resid_math`
- `resid_read`
- `bto_math`
- `bto_read`

**Ask Yourself**

- How many schools are performing better than expected given their student characteristics? How many are performing worse than expected?
- How does school performance vary by subject area?

**Possible Next Steps or Action Plans:** Identity which schools are performing at different levels. Develop academic plan for schools at each performance level.

**Analytic Technique:** Count the number of schools by performance level. Plot a matrix to compare school performance across subject areas.  

```{r bto-cuts-plot, echo=TRUE}
# // Step 1: Determine performance levels
# We examined the distribution of BTO schools as one example
# of how to determine performance levels. We recognize that 
# are a number of other ways to establish performance levels.
# Examples include, referecing academic literature, technical
# documents, pilot studies, statistical analyses, etc.
df_bto %>% 
  mutate(bto_math = ifelse(bto_math == "yes", "Yes", "No")) %>%
  ggplot(aes(resid_math)) +
  geom_histogram(aes(fill = bto_math), alpha = .8) +
  scale_fill_manual(values = c("#E69F00", "#999999")) +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 11),
        legend.position = "top",
        legend.text = element_text(size = 11)) +
  labs(x = "Math (actual - predicted)", y = "Number of Schools", fill = "",
       title = "Distribution of Beating-the-Odds Schools in Math") 

# // Step 2: Set performance levels
df_cuts <- df_bto %>% 
  # Set performance cuts for math
  mutate(perf_math = case_when(
    # No difference
    bto_math == "no" ~ 0,
    # Significant positive difference
    bto_math == "yes" & between(resid_math, 0, .5) ~ 1,
    bto_math == "yes" & between(resid_math, .5, 1) ~ 2,
    bto_math == "yes" & resid_math > 1 ~ 3,
    # Significant negative difference
    bto_math == "yes" & between(resid_math, -.5, 0) ~ -1,
    bto_math == "yes" & between(resid_math, -1, -.5) ~ -2,
    bto_math == "yes" & resid_math < -1 ~ -3
  )) %>% 
  # Set performance cuts for reading, repete previous steps
  mutate(perf_read = case_when(
    bto_read == "no" ~ 0,
    bto_read == "yes" & between(resid_read, 0, .5) ~ 1,
    bto_read == "yes" & between(resid_read, .5, 1) ~ 2,
    bto_read == "yes" & resid_read > 1 ~ 3,
    bto_read == "yes" & between(resid_read, -.5, 0) ~ -1,
    bto_read == "yes" & between(resid_read, -1, -.5) ~ -2,
    bto_read == "yes" & resid_read < -1 ~ -3
  ))

# // Step 2: Create temp datasets for plotting
df_math <- df_cuts %>% 
  count(perf_math) %>% 
  mutate(subject = "Math") %>% 
  select(subject, cut = perf_math, n)

df_read <- df_cuts %>% 
  count(perf_read) %>% 
  mutate(subject = "Reading") %>% 
  select(subject, cut = perf_read, n)

# // Step 3: Plot
bind_rows(df_math, df_read) %>% 
  mutate(cut = case_when(
    cut == -3 ~ "Large\nnegative\ndecrease",
    cut == -2 ~ "Medium\nnegative\ndecrease",
    cut == -1 ~ "Small\nnegative\ndecrease",
    cut == 0 ~ "No\nsignificant\ndecrease",
    cut == 1 ~ "Small\npositive\nincrease",
    cut == 2 ~ "Medium\npositive\nincrease",
    cut == 3 ~ "Large\npositive\nincrease"
  )) %>% 
  mutate(cut = fct_relevel(
    cut, 
    "Large\nnegative\ndecrease", "Medium\nnegative\ndecrease", 
    "Small\nnegative\ndecrease", "No\nsignificant\ndecrease", 
    "Small\npositive\nincrease", "Medium\npositive\nincrease", 
    "Large\npositive\nincrease")) %>% 
  filter(!is.na(cut)) %>% 
  ggplot(aes(cut, n, fill = subject)) +
  geom_col(position = position_dodge(.85), width = .8) +
  geom_text(aes(label = n),
            position = position_dodge(.85), vjust = -.45) +
  scale_fill_manual(values = c("#E69F00", "#999999")) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title.y = element_text(size = 12),
        axis.title.x = element_blank(),
        axis.text = element_text(size = 11),
        legend.position = "top",
        legend.text = element_text(size = 11)) +
  labs(x = "", y = "Number of Schools", fill = "",
       title = "Distribution of Beating-the-Odds Schools in Math and Reading") 
```

Creating tables or plots that compare school performance levels in math and reading allows us to see whether schools perform better or worse in one or two subject areas. In this example, we see that school performance in math and reading are correlated. This information can be used to inform the way we think about best practices.

```{r bto-cuts-table, echo=TRUE}
# Plot table
df_cuts %>%
  # Recode variable for plotting
  mutate(perf_math = case_when(
    perf_math == -3 ~ "Large\nnegative\ndecrease",
    perf_math == -2 ~ "Medium\nnegative\ndecrease",
    perf_math == -1 ~ "Small\nnegative\ndecrease",
    perf_math == 0 ~ "No\nsignificant\ndecrease",
    perf_math == 1 ~ "Small\npositive\nincrease",
    perf_math == 2 ~ "Medium\npositive\nincrease",
    perf_math == 3 ~ "Large\npositive\nincrease"
  )) %>% 
  mutate(perf_math = fct_relevel(
    perf_math, 
    "Large\nnegative\ndecrease", "Medium\nnegative\ndecrease", 
    "Small\nnegative\ndecrease", "No\nsignificant\ndecrease", 
    "Small\npositive\nincrease", "Medium\npositive\nincrease", 
    "Large\npositive\nincrease")) %>%
  mutate(perf_read = case_when(
    perf_read == -3 ~ "Large\nnegative\ndecrease",
    perf_read == -2 ~ "Medium\nnegative\ndecrease",
    perf_read == -1 ~ "Small\nnegative\ndecrease",
    perf_read == 0 ~ "No\nsignificant\ndecrease",
    perf_read == 1 ~ "Small\npositive\nincrease",
    perf_read == 2 ~ "Medium\npositive\nincrease",
    perf_read == 3 ~ "Large\npositive\nincrease"
  )) %>% 
  mutate(perf_read = fct_relevel(
    perf_read, 
    "Large\nnegative\ndecrease", "Medium\nnegative\ndecrease", 
    "Small\nnegative\ndecrease", "No\nsignificant\ndecrease", 
    "Small\npositive\nincrease", "Medium\npositive\nincrease", 
    "Large\npositive\nincrease")) %>%
  # Drop missing values for plotting
  drop_na(perf_math, perf_read) %>%
  # Count number of schools by performance levels
  count(perf_math, perf_read) %>%
  ggplot(aes(perf_math, perf_read)) +
  geom_tile(fill = "white") +
  geom_text(aes(label = n)) +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 11)) +
  labs(x = "Math Performance", y = "Reading Performance",
       title = "School Counts by Performance Categories for Math and Reading")
```

### BTO schools by student demographics

**Purpose:** This analysis explores the student demographics of schools at different performance levels. 

**Required Analysis File Variables:**

- `chrt_ninth`
- `sch_white`
- `sch_frpl`
- `sch_sped`
- `sch_lep`
- `resid_math`
- `resid_read`

**Ask Yourself**

- Do student populations differ for high- and low-performing schools?
- How do high-/low-performing schools compare to all school?

**Analytic Technique:** Calculate the percentage of white (or minority) students, low income students, and special education students for schools in each performance level. 

```{r bto-demos, echo=TRUE}
# // Step 1: Create temp datasets for plotting
grp_all <- df_sch_avg %>% 
  filter(chrt_ninth == 2010) %>% 
  summarise(prop_white = mean(sch_white, na.rm = TRUE),
            prop_frpl = mean(sch_frpl, na.rm = TRUE),
            prop_sped = mean(sch_sped, na.rm = TRUE),
            prop_lep = mean(sch_lep, na.rm = TRUE)) %>% 
  mutate(group = "All students") %>% 
  pivot_longer(-group)

grp_math <- df_cuts %>%
  mutate(perf_math_high_low = case_when(
    perf_math > 0 ~ "High performing",
    perf_math < 0 ~ "Low performing",
    perf_math == 0 ~ "Other"
  )) %>%
  left_join(df_sch_avg %>% filter(chrt_ninth == 2010)) %>% 
  drop_na(perf_math_high_low) %>% 
  group_by(perf_math_high_low) %>% 
  summarise(prop_white = mean(sch_white, na.rm = TRUE),
            prop_frpl = mean(sch_frpl, na.rm = TRUE),
            prop_sped = mean(sch_sped, na.rm = TRUE),
            prop_lep = mean(sch_lep, na.rm = TRUE)) %>% 
  pivot_longer(cols = starts_with("prop")) %>% 
  rename(group = perf_math_high_low)

grp_read <- df_cuts %>%
  mutate(perf_read_high_low = case_when(
    perf_read > 0 ~ "High performing",
    perf_read < 0 ~ "Low performing",
    perf_read == 0 ~ "Other"
  )) %>%
  left_join(df_sch_avg %>% filter(chrt_ninth == 2010)) %>% 
  drop_na(perf_read_high_low) %>% 
  group_by(perf_read_high_low) %>% 
  summarise(prop_white = mean(sch_white, na.rm = TRUE),
            prop_frpl = mean(sch_frpl, na.rm = TRUE),
            prop_sped = mean(sch_sped, na.rm = TRUE),
            prop_lep = mean(sch_lep, na.rm = TRUE)) %>% 
  pivot_longer(cols = starts_with("prop")) %>% 
  rename(group = perf_read_high_low) 

# // Step 2: Plot

# Math
bind_rows(grp_all, grp_math) %>% 
  # Recode variables for plotting
  mutate(group = fct_relevel(
    group, "All students", "High performing","Low performing", "Other"
    )) %>% 
  mutate(value = round(value * 100, 1)) %>% 
  mutate(name = case_when(
    name == "prop_white" ~ "White",
    name == "prop_frpl" ~ "Low Income",
    name == "prop_sped" ~ "Special Education",
    name == "prop_lep" ~ "Limited English"
  )) %>% 
  ggplot(aes(name, value, fill = group)) +
  geom_col(position = position_dodge(.85), width = .8) +
  geom_text(aes(label = round(value, 1)),
            position = position_dodge(.85), vjust = -.45) +
  expand_limits(y = c(0, 100)) +
  scale_fill_manual(values = c("#999999", "#E69F00", "#56B4E9", "#009E73")) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 12),
        axis.text = element_text(size = 11),
        legend.position = "top",
        legend.text = element_text(size = 11)) +
  labs(x = "", y = "Percent of Students", fill = "",
       title = "School Demographics by Performance Status in Math")

# Reading
bind_rows(grp_all, grp_read) %>% 
  mutate(group = fct_relevel(
    group, "All students", "High performing","Low performing", "Other"
  )) %>% 
  mutate(value = round(value * 100, 1)) %>% 
  mutate(name = case_when(
    name == "prop_white" ~ "White",
    name == "prop_frpl" ~ "Low Income",
    name == "prop_sped" ~ "Special Education",
    name == "prop_lep" ~ "Limited English"
  )) %>% 
  ggplot(aes(name, value, fill = group)) +
  geom_col(position = position_dodge(.85), width = .8) +
  geom_text(aes(label = round(value, 1)),
            position = position_dodge(.85), vjust = -.45) +
  expand_limits(y = c(0, 100)) +
  scale_fill_manual(values = c("#999999", "#E69F00", "#56B4E9", "#009E73")) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 12),
        axis.text = element_text(size = 11),
        legend.position = "top",
        legend.text = element_text(size = 11)) +
  labs(x = "", y = "Percent of Students", fill = "",
       title = "School Demographics by Performance Status in Reading")
```

---

##### *This guide was originally created by Aaron Butler and Hannah Poquette in partnership with the Strategic Data Project.*